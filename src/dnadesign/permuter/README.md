# **permuter**

*A bioinformatic pipeline for systematic permutation and **multi-metric** evaluation of biological sequences.*

---

## Overview

Given one or more reference sequences, **permuter** can

1. **Permute**

   * Nucleotide swapping â€“ `scan_dna`
   * Codon swapping â€“ `scan_codon` (requires a codon lookup table)

2. **Evaluate** each variant with pluggable **Evaluators** (per metric)

   * `log_likelihood` (LL)
   * `log_likelihood_ratio` (LLR) versus the reference
   * `embedding_distance` (negative Euclidean to the reference embedding; larger = better)

3. **Combine** metrics via an **objective** (e.g., `weighted_sum` with per-metric weights).

4. **Select** elites using a **strategy** (`top_k` or `threshold`).

5. **Iterate** permutation â†’ evaluation â†’ objective â†’ selection for *N* rounds (optional).

6. **Report** JSONL (+ optional CSV) and any plots you request.

---

## Quick start

```bash
# 1) Put your references in CSV (two columns): ref_name,sequence
#    See: dnadesign/permuter/input/refs.csv

# 2) Run an example config (see full example below)
python -m dnadesign.permuter.main --config my_config.yaml
```

### â€œPlots-onlyâ€ / analysis without recompute

If you already have JSONL outputs in `batch_results/<job>_<ref>/`:

```yaml
run:
  mode: analysis   # only (re)generate plots/CSVs from existing JSONL
```

Or let **permuter** decide automatically:

```yaml
run:
  mode: auto       # if outputs exist â†’ plots-only; else â†’ full pipeline
```

---

## Configuration

Define behavior in `config.yaml`.

```yaml
# dnadesign/permuter/config.yaml

permuter:
  experiment:
    name: demo

  jobs:
    - name: example_scan
      input_file: dnadesign/permuter/input/refs.csv
      references: ["retron_Eco1_msr_msd_wt"]

      # run mode
      run:
        mode: full                # one of: full | analysis | auto

      permute:
        protocol: scan_dna        # scan_dna | scan_codon | ...
        regions: []               # [] = full sequence; or [[start,end), â€¦]
        lookup_tables: []         # e.g. ["dnadesign/permuter/input/codon_ecoli.csv"] for scan_codon

      evaluate:
        metrics:
          - id: ll
            name: log_likelihood
            evaluator: placeholder
            goal: max
            norm: {method: rank, scope: round}
          - id: llr
            name: log_likelihood_ratio
            evaluator: placeholder
            goal: max
            norm: {method: rank, scope: round}

      select:
        objective:
          type: weighted_sum
          weights: { ll: 0.7, llr: 0.3 }  # keys must match metric ids
        strategy:
          type: top_k
          k: 10
          include_ties: true

      iterate:
        enabled: true
        total_rounds: 3

      report:
        csv: true
        plots:
          - scatter_metric_by_position
```

#### Threshold strategy

You can threshold the **objective** or a specific **metric** (by id). Use either a **numeric threshold** or a **percentile**.

**Objective percentile (top 20% by objective):**

```yaml
select:
  objective:
    type: weighted_sum
    weights: { ll: 0.5, llr: 0.5 }
  strategy:
    type: threshold
    target: objective
    percentile: 80            # keep variants >= 80th percentile (within round)
```

**Metric threshold (normalized metric id `llr`, keep >= 0.8):**

```yaml
select:
  objective:
    type: weighted_sum
    weights: { ll: 0.5, llr: 0.5 }
  strategy:
    type: threshold
    target: metric
    metric_id: llr
    use_normalized: true      # default; keeps 0..1, goal-aware
    threshold: 0.8
```

> If you set `target: metric` and use `percentile`, you must use `use_normalized: true` (default).


---

#### Directory layout

```
dnadesign/permuter/
â”œâ”€â”€ main.py                        # single entry-point
â”œâ”€â”€ config.py                      # YAML validator
â”œâ”€â”€ logging_utils.py
â”œâ”€â”€ evaluate.py                    # multi-metric evaluation helpers
â”œâ”€â”€ permute_record.py
â”œâ”€â”€ reporter.py                    # JSONL/CSV + dynamic plotting
â”‚
â”œâ”€â”€ protocols/                     # mutation strategies
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scan_dna.py
â”‚   â””â”€â”€ scan_codon.py              # (if present) requires lookup table
â”‚
â”œâ”€â”€ evaluators/                    # scoring back ends
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py
â”‚   â””â”€â”€ placeholder.py             # deterministic stub (no GPU)
â”‚
â”œâ”€â”€ selector/                      # ğŸ”Œ selection plugins
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ objectives/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â””â”€â”€ weighted_sum.py
â”‚   â””â”€â”€ strategies/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py
â”‚       â”œâ”€â”€ top_k.py
â”‚       â””â”€â”€ threshold.py
â”‚
â”œâ”€â”€ plots/                         # ğŸ”Œ drop-in visualisations
â”‚   â””â”€â”€ scatter_metric_by_position.py
â”‚
â””â”€â”€ input/                         # user data
    â”œâ”€â”€ refs.csv                   # required columns: ref_name,sequence
    â””â”€â”€ codon_ecoli.csv            # example codon table
```

Outputs land in `batch_results/<job>_<ref>/`.

---

## Output files

```
batch_results/lacI_scan_lacI/
â”œâ”€â”€ MANIFEST.json
â”œâ”€â”€ config_snapshot.yaml
â”œâ”€â”€ r1_variants.jsonl
â”œâ”€â”€ r1_elites.jsonl
â”œâ”€â”€ norm_stats_r1.json
â”œâ”€â”€ r2_variants.jsonl
â”œâ”€â”€ r2_elites.jsonl
â”œâ”€â”€ norm_stats_r2.json
â”œâ”€â”€ plots/
â”‚   â””â”€â”€ lacI_scan_scatter_metric_by_position.png
â”œâ”€â”€ lacI_scan.csv                  # optional (report.csv: true)
â””â”€â”€ lacI_scan_elites.csv           # optional (report.csv: true)
```

### JSONL record (example)

```json
{
  "var_id": "FQ2FZ8S1L1GX",
  "parent_var_id": "9K7U5Z4YB2QC",
  "job_name": "lacI_scan",
  "ref_name": "lacI",
  "protocol": "scan_dna",
  "round": 2,
  "sequence": "ACGTâ€¦",
  "modifications": ["A5T","G12C"],
  "metrics": {"llr": 0.14, "emb": -0.82},
  "norm_metrics": {"llr": 0.73, "emb": 0.58},
  "objective_score": 0.684,
  "objective_meta": {
    "type": "weighted_sum",
    "weights": {"llr": 0.7, "emb": 0.3},
    "norm_scope": "round",
    "norm_stats_id": "r2_9A3F10"
  }
}
```

---

## Extending **permuter**

| Want to add â€¦           | Where / how                                                                                 |
| ----------------------- | ------------------------------------------------------------------------------------------- |
| **Mutation protocol**   | Create `permuter/protocols/my_protocol.py` with `generate_variants()`                       |
| **Evaluator / model**   | Subclass `evaluators.base.Evaluator`, register in `evaluators/__init__.py`                  |
| **Objective (combine)** | Add under `selector/objectives/`, subclass `Objective`, register in `__init__.py`           |
| **Strategy (select)**   | Add under `selector/strategies/`, subclass `Strategy`, register in `__init__.py`            |
| **Plot**                | Drop a module in `permuter/plots/` exposing `plot(elite_df, all_df, output_path, job_name)` |

---

Eric J. South (ericjohnsouth@gmail.com)
