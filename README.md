# dnadesign

`dnadesign` is a collection of modular bioinformatic pipelines and helper packages related to DNA sequence design.

### Directory Layout
```text
dnadesign/
├── README.md            # High-level project documentation
├─ uv.lock
└── src/
    └── dnadesign/ 
        ├── usr/         # Parquet-backed datasets + CLI
        ├── infer/       # model-agnostic inference (Evo2 adapter)
        ├── densegen/    # solver-backed promoter assembly           
        ├── cruncher/     
        └── ...
```
     
### Pipelines

1. [**usr**](src/dnadesign/usr) 

      **usr (Universal Sequence Record)** is the centralized repository and API for datasets of biological sequences used across the `dnadesign` ecosystem.

      ```python
      usr/
      ├─ src/
      └─ datasets/             # default root for dataset folders
           └─ <dataset_name>/
                ├─ records.parquet
                ├─ .events.log
                └─ .snapshots/
      ```
      
      **usr** represents as single source of truth: one Parquet file per dataset with sequences + metadata + derived representations. Sibling pipelines can read/write their own namespaced columns without breaking other workflows.

2. [**densegen**](src/dnadesign/densegen) 
   
      **densegen** is a DNA sequence design pipeline built on the integer linear programming framework from the [**dense-arrays**](https://github.com/e-south/dense-arrays) package. It assembles batches of synthetic promoters, each composed of densely packed transcription factor binding sites. The pipeline references curated datasets from the [**deg2tfbs**](https://github.com/e-south/deg2tfbs) repository, subsampling dozens of binding sites to feed into the solver, with time limits enforced to prevent stalling.

2. [**infer**](src/dnadesign/infer)  

      **infer** is a model-agnostic wrapper for DNA/protein language models (e.g., Evo2).


3. [**opal**](src/dnadesign/opal)

      WIP.

3. [**clustering**](src/dnadesign/clustering) 
  
      **clustering** utilizes [Scanpy](https://scanpy.readthedocs.io/en/stable/) for cluster analysis on nucleotide sequences stored in the sibling **sequences** directory. By default, it uses mean-pooled output embeddings from **Evo 2** (e.g., a 1 × 512 vector) as input. The pipeline then generates UMAP embeddings, applies Leiden clustering, and also supports downstream analyses, such as cluster composition and diversity assessment.

4. [**billboard**](src/dnadesign)  

      **billboard** quantifies the regulatory diversity of dense-array DNA libraries generated by **densegen**. The pipeline reports and visualizes metrics such as TF richness, TF usage balance (Gini), TF combinatorial diversity (Jaccard), and TF spatial entropy across sequences.

5.  [**libshuffle**](src/dnadesign/libshuffle)

      **libshuffle** iteratively subsamples sequence libraries from the sibling **sequences** directory and computes diversity metrics using the **billboard** pipeline as its engine. It can be used to visualize and select representative subsamples of sequences based on configured diversity metrics.

6.	[**nmf**](src/dnadesign/nmf)

      **nmf** applies Non-Negative Matrix Factorization (NMF) to a library of sequences generated by **densegen** to uncover higher-order transcription factor binding site combinations.

7.  [**latdna**](src/dnadesign/latdna)

      **latdna** is a pipeline for latent space analysis of DNA sequences. It computes pairwise distances between Evo 2 embeddings within groups of sequences using metrics such as cosine and Euclidean distance. These distances are used to characterize intra-population diversity and compare it across different sequence types, including dense arrays, natural promoters, and engineered promoters.

8. [**cruncher**](src/dnadesign/cruncher)

      **cruncher** is a pipeline that parses TF position-weight matrices (MEME, JASPAR, etc.) via plug-in parsers, and then runs a discrete Categorical Gibbs optimiser (or other plug-ins) to discover short DNA sequences that score highly on one or more TFs.

9. [**tfkdanalysis**](src/dnadesign/tfkdanalysis)

      **tfkdanalysis** is a pipeline for analyzing transcription factor knockdown (TFKD) effects using PPTP-seq (Promoter responses to TF perturbation sequencing) data—a high-throughput approach described in [Han *et al.* (2023)](https://doi.org/10.1038/s41467-023-41572-4).

12. [**aligner**](src/dnadesign/aligner)

      **aligner** is a wrapper for Biopython's [PairwiseAligner](https://biopython.org/docs/dev/Tutorial/chapter_pairwise.html#chapter-pairwise), which is a class for computing Needleman–Wunsch global alignment scores between nucleotide sequences.

13. [**permuter**](src/dnadesign/permuter)

      **permuter** permuter is a pipeline for biological sequence permutation and subsequent evaluation workflows.
14. [**archived**](src/dnadesign/archived)

      **archived** contains a mix of old legacy projects and prototypes.

## Quickstart

### 1. Install UV
```bash
curl -Ls https://astral.sh/uv/install | sh
# ensure ~/.local/bin (or your UV bin dir) is on PATH
```

#### 2. Grab the source
```bash
git clone https://github.com/e-south/dnadesign.git
cd dnadesign
```

#### 3. Create & activate the venv
```bash
uv venv --python 3.12        # creates .venv/
source .venv/bin/activate
which python                 # sanity → …/dnadesign/.venv/bin/python
```

#### 4. Reproduce the dependency graph (from uv.lock)
```bash
uv sync
```

#### 5. Editable install (dev tools, linters, tests)
```bash
uv pip install -e .[dev]
```

#### 6. (Optional) dense-arrays as a sibling
```bash
# from the parent dir of dnadesign/
git clone https://gitlab.com/dunloplab/dense-arrays.git
uv pip install -e ./dense-arrays
```

#### 7. Sanity checks
```bash
python -c "import dnadesign, pyarrow, pandas; print('ok')"
python -m dnadesign.usr ls || true
```
### (Optional) Extended installation for resource-intensive  workflows
Some pipelines are more resource-intensive and are designed to run on a [shared computing cluster](https://www.bu.edu/tech/support/research/system-usage/connect-scc/scc-ondemand/), such as solving dense arrays with [Gurobi](https://www.gurobi.com/), or running inference with [Evo 2](https://github.com/ArcInstitute/evo2).

##### 1. Cluster setup

In practice you can:

- create/sync the repo’s UV environment,
- layer PyTorch built for your node’s CUDA,
- add Transformer Engine and FlashAttention,
- install Evo2 from PyPI, and
- run pipelines.

Below uses CUDA 12.6 wheels as an example; change the index URL to match your cluster’s CUDA toolchain.

#####  2. (Optional) Request an interactive GPU session
SCC Interactive Session Resource Request Example:

> - **densegen** workflow:
>   - Modules: miniconda gurobi
>   - Cores: 16  
>   - GPUs: 0  
> - **evoinference** workflow:  
>   - Modules: cuda miniconda
>   - Cores: 3  
>   - GPUs: 1  
>   - GPU Compute Capability: 8.9  
>   - Extra options: `-l mem_per_core=8G`  

Check your cluster documentation for submission details.

##### 3. Load site toolchains

```bash
module load cuda/12.5         # Load the CUDA module appropriate for your cluster
module load gcc/10.2.0        # Load a GCC version that is compatible with CUDA

# Optional sanity; verify that nvcc is available:
ls $CUDA_HOME/bin/nvcc
nvcc --version && gcc --version             
```

##### 4. Create and sync the base env (from repo root)
```bash
uv venv --python 3.12         # 3.12 required for Evo2
source .venv/bin/activate
uv sync                       # uses the checked-in uv.lock
```

##### 4. Install PyTorch for your CUDA

Installing PyTorch built for CUDA ensures that GPU acceleration is enabled for Evo 2’s computations. Here, we install a version built for CUDA 12.6, which is optimal for GPUs with compute capability ≥8.9.

```bash
# Example: CUDA 12.6 wheels
pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 \
  --index-url https://download.pytorch.org/whl/cu126
```

> **Note:** If your GPU does not support FP8 or if you encounter compatibility issues, consider installing a version built for a different CUDA (e.g., cu118).

##### 5. Install Transformer Engine + FlashAttention
```bash
# FlashAttention (prebuilt wheels; no build isolation is recommended upstream)
pip install flash-attn==2.8.0.post2 --no-build-isolation

# Transformer Engine (PyPI)
pip install transformer-engine>=2.0.0
```
##### 6. Install Evo2 (PyPI)

```bash
pip install evo2
```

##### 7. Validate the install

```bash
# single-GPU 7B
python -m evo2.test.test_evo2_generation --model_name evo2_7b
```

##### Lockfile hygiene with UV

Keep the base env managed by uv sync, and overlay Torch/TE/FA/Evo2 on the GPU nodes via pip (or site modules).

```python
uv add --extra infer-evo2 evo2
uv add flash-attn==2.8.0.post2
uv add transformer-engine>=2.0.0
uv lock && uv sync
```

Add packages to the project and update uv.lock as needed.
```bash
uv add <pkg>==<ver>
# remove
uv remove <pkg>
# upgrade a specific package in the lock
uv lock --upgrade-package <pkg>
# enforce exact lock during CI
uv sync --frozen
```

---

@e-south
