# dnadesign

`dnadesign` is a collection of modular bioinformatic pipelines and helper packages related to DNA sequence design.

### Directory Layout
```text
dnadesign/
├── README.md            # High-level project documentation
├─ uv.lock
└── src/
    └── dnadesign/ 
        ├── usr/         # sequence datasets
        ├── infer/       # model-agnostic inference (Evo2 adapter)
        ├── densegen/    # solver-backed promoter assembly           
        ├── opal/     
        └── ...
```
     
### Pipelines

1. [**usr**](src/dnadesign/usr) 

      **usr (Universal Sequence Record)** is the centralized repository and API for datasets of biological sequences used across the `dnadesign` ecosystem.

      ```python
      usr/
      ├─ src/
      └─ datasets/                  # default root for dataset folders
           └─ <dataset_name>/
                ├─ records.parquet  # data lives here
                ├─ .events.log      # action history
                └─ _snapshots/
      ```
      
      **usr** represents as single source of truth: one Parquet file per dataset with sequences + metadata + derived representations. Sibling pipelines can read/write their own namespaced columns without breaking other workflows.

2. [**densegen**](src/dnadesign/densegen) 
   
      **densegen** is a DNA sequence design pipeline built on the integer linear programming framework from the [**dense-arrays**](https://github.com/e-south/dense-arrays) package. It assembles batches of synthetic promoters, each composed of densely packed transcription factor binding sites. The pipeline references curated datasets from the [**deg2tfbs**](https://github.com/e-south/deg2tfbs) repository, subsampling dozens of binding sites to feed into the solver, with time limits enforced to prevent stalling.

2. [**infer**](src/dnadesign/infer)  

      **infer** is a model-agnostic wrapper for DNA/protein language models (e.g., [Evo2](https://github.com/ArcInstitute/evo2/tree/main)).

3. [**opal**](src/dnadesign/opal)

      **opal** is an [EVOLVEpro-style](https://www.science.org/doi/10.1126/science.adr6006) active-learning tool for DNA/protein sequence design campaigns. Provide a feature column (X) and a label column (Y); OPAL trains a regressor, predicts Ŷ for all sequence candidates, and selects the top-k each round.

3. [**clustering**](src/dnadesign/clustering) 
  
      **clustering** utilizes [Scanpy](https://scanpy.readthedocs.io/en/stable/) for cluster analysis on nucleotide sequences stored in the sibling **sequences** directory. By default, it uses mean-pooled output embeddings from **Evo 2** (e.g., a 1 × 512 vector) as input. The pipeline then generates UMAP embeddings, applies Leiden clustering, and also supports downstream analyses, such as cluster composition and diversity assessment.

4. [**billboard**](src/dnadesign)  

      **billboard** quantifies the regulatory diversity of dense-array DNA libraries generated by **densegen**. The pipeline reports and visualizes metrics such as TF richness, TF usage balance (Gini), TF combinatorial diversity (Jaccard), and TF spatial entropy across sequences.

5.  [**libshuffle**](src/dnadesign/libshuffle)

      **libshuffle** iteratively subsamples sequence libraries from the sibling **sequences** directory and computes diversity metrics using the **billboard** pipeline as its engine. It can be used to visualize and select representative subsamples of sequences based on configured diversity metrics.

6.	[**nmf**](src/dnadesign/nmf)

      **nmf** applies Non-Negative Matrix Factorization (NMF) to a library of sequences generated by **densegen** to uncover higher-order transcription factor binding site combinations.

7.  [**latdna**](src/dnadesign/latdna)

      **latdna** is a pipeline for latent space analysis of DNA sequences. It computes pairwise distances between Evo 2 embeddings within groups of sequences using metrics such as cosine and Euclidean distance. These distances are used to characterize intra-population diversity and compare it across different sequence types, including dense arrays, natural promoters, and engineered promoters.

8. [**cruncher**](src/dnadesign/cruncher)

      **cruncher** is a pipeline that parses TF position-weight matrices (MEME, JASPAR, etc.) via plug-in parsers, and then runs a discrete Categorical Gibbs optimiser (or other plug-ins) to discover short DNA sequences that score highly on one or more TFs.

9. [**tfkdanalysis**](src/dnadesign/tfkdanalysis)

      **tfkdanalysis** is a pipeline for analyzing transcription factor knockdown (TFKD) effects using PPTP-seq (Promoter responses to TF perturbation sequencing) data—a high-throughput approach described in [Han *et al.* (2023)](https://doi.org/10.1038/s41467-023-41572-4).

12. [**aligner**](src/dnadesign/aligner)

      **aligner** is a wrapper for Biopython's [PairwiseAligner](https://biopython.org/docs/dev/Tutorial/chapter_pairwise.html#chapter-pairwise), which is a class for computing Needleman–Wunsch global alignment scores between nucleotide sequences.

13. [**permuter**](src/dnadesign/permuter)

      **permuter** permuter is a pipeline for biological sequence permutation and subsequent evaluation workflows.
14. [**archived**](src/dnadesign/archived)

      **archived** contains a mix of old legacy projects and prototypes.

## Quickstart

### 1. Install UV
```bash
curl -Ls https://astral.sh/uv/install | sh
# ensure ~/.local/bin (or your UV bin dir) is on PATH
```

#### 2. Grab the source
```bash
git clone https://github.com/e-south/dnadesign.git
cd dnadesign
```

#### 3. Create & activate the venv
```bash
uv venv --python 3.12        # creates .venv/
source .venv/bin/activate
which python                 # sanity → …/dnadesign/.venv/bin/python
```

#### 4. Reproduce the dependency graph (from uv.lock)
```bash
uv sync
```

#### 5. Editable install (dev tools, linters, tests)
```bash
uv pip install -e .[dev]
```

#### 6. (Optional) dense-arrays as a sibling
```bash
# from the parent dir of dnadesign/
git clone https://gitlab.com/dunloplab/dense-arrays.git
uv pip install -e ./dense-arrays
```

#### 7. Sanity checks
```bash
python -c "import dnadesign, pyarrow, pandas; print('ok')"
python -m dnadesign.usr ls || true
```
### (Optional) Alternative installation for resource-intensive  workflows
Some pipelines are more resource-intensive and are designed to run on a [shared computing cluster](https://www.bu.edu/tech/support/research/system-usage/connect-scc/scc-ondemand/), such as solving dense arrays with [Gurobi](https://www.gurobi.com/), or running inference with [Evo 2](https://github.com/ArcInstitute/evo2).

In practice you can:

- clone this repo,
- create/sync the repo’s UV environment,
- layer PyTorch built for your node’s CUDA,
- add Transformer Engine and FlashAttention,
- install Evo2 from PyPI, and
- run pipelines.

Below uses CUDA 12.6 wheels as an example; change the index URL to match your cluster’s CUDA toolchain.

#####  1. (Optional) Request an interactive GPU session
SCC Interactive Session Resource Request Example:

> - **densegen** workflow:
>   - Modules: miniconda gurobi
>   - Cores: 16  
>   - GPUs: 0  
> - **evoinference** workflow:  
>   - Modules: cuda miniconda
>   - Cores: 3  
>   - GPUs: 1  
>   - GPU Compute Capability: 8.9  
>   - Extra options: `-l mem_per_core=8G`  

Check your cluster documentation for submission details.

##### 2. Install UV
```bash
curl -Ls https://astral.sh/uv/install | sh
# ensure ~/.local/bin (or your UV bin dir) is on PATH
```

##### 3. Put UV caches on project space
Add this once to your ~/.bashrc (or run it inline before installing):
```bash
# --- uv cache/temp on project space (HPC) ---
export UV_CACHE_DIR="${UV_CACHE_DIR:-/project/dunlop/esouth/.uvcache}"
export UV_LINK_MODE=copy
export TMPDIR="${TMPDIR:-/project/dunlop/esouth/.uvtmp}"
[ -d "$UV_CACHE_DIR" ] || mkdir -p "$UV_CACHE_DIR"
[ -d "$TMPDIR" ] || mkdir -p "$TMPDIR"
# Avoid picking up user-site packages (~/.local) that can conflict
export PYTHONNOUSERSITE=1
# --- end uv config ---
```
Reload your shell:
```bash
source ~/.bashrc
```

##### 4. Grab the source
```bash
git clone https://github.com/e-south/dnadesign.git
cd dnadesign
```

##### 5. Create and activate the base env (from repo root)
```bash
uv python install 3.12
uv venv --python 3.12         # 3.12 required for Evo2
source .venv/bin/activate
which python
```

##### 6. Reproduce base deps (from uv.lock) + dev extras
```bash
uv sync                       # uses the uv.lock file
uv pip install -e .[dev]
```

##### 7. Load cluster CUDA toolchain (match to your node)

```bash
module load cuda/12.5         # Load the CUDA module appropriate for your cluster
module load gcc/10.2.0        # Load a GCC version that is compatible with CUDA

# Sanity; verify that nvcc is available:
ls $CUDA_HOME/bin/nvcc
nvcc --version && gcc --version  

# explicit paths (adjust for your site if needed)
export CUDA_HOME=/share/pkg.8/cuda/12.5/install
export CUDA_PATH=$CUDA_HOME
export CUDACXX=$CUDA_HOME/bin/nvcc
export PATH=$CUDA_HOME/bin:$PATH

export CC=/share/pkg.7/gcc/10.2.0/install/bin/gcc
export CXX=/share/pkg.7/gcc/10.2.0/install/bin/g++
```

> GPU arch hint: set the SM you actually run on.
> Ada (e.g., L40S/4090): export TORCH_CUDA_ARCH_LIST=8.9
> H100: export TORCH_CUDA_ARCH_LIST=9.0

```bash
export TORCH_CUDA_ARCH_LIST="${TORCH_CUDA_ARCH_LIST:-8.9}"
export FORCE_CUDA=1
```

##### 8. Install PyTorch matched to your CUDA

Installing PyTorch built for CUDA ensures that GPU acceleration is enabled for Evo 2’s computations. Here, we install a version built for CUDA 12.6, which is optimal for GPUs with compute capability ≥8.9.

```bash
# Example: CUDA 12.6 wheels
uv pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 \
  --index-url https://download.pytorch.org/whl/cu126
```

> **Note:** If your GPU does not support FP8 or if you encounter compatibility issues, consider installing a version built for a different CUDA (e.g., cu118).

Quick check:
```bash
python - <<'PY'
import torch
print("Torch:", torch.__version__, "CUDA:", torch.version.cuda, "avail:", torch.cuda.is_available())
PY
```

##### 9. Install Transformer Engine (builds the PyTorch extension)
Install the TE meta-package with the PyTorch extra (this pulls and builds transformer-engine-torch to match your toolchain):
```bash
uv pip install --no-build-isolation "transformer-engine[pytorch]==2.6.0.post1"
```

Sanity:
```bash
python - <<'PY'
from transformer_engine.pytorch import Linear
print("TransformerEngine Linear OK")
PY
```

##### 10. Build FlashAttention from source
```bash
# Helpful build tools
uv pip install ninja packaging

# Ensure we don't keep an incompatible wheel around
# (if prompted to uninstall, confirm)
uv pip uninstall flash-attn || true

git clone https://github.com/Dao-AILab/flash-attention.git
cd flash-attention
# Optionally checkout a specific tag, e.g. v2.8.0.post2 or latest stable
# git checkout v2.8.3
```

Verify FA + TE load together:
```bash
python - <<'PY'
import importlib.util as iu, torch
print("Torch:", torch.__version__, "CUDA:", torch.version.cuda, "avail:", torch.cuda.is_available())
print("flash-attn present:", iu.find_spec("flash_attn") is not None)
from transformer_engine.pytorch import Linear
print("TE Linear OK (with FlashAttention)")
PY
```

##### 11. Install Evo2 (PyPI)

```bash
uv pip install evo2
```

##### 12. Validate the install

```bash
# single-GPU 7B
python -m evo2.test.test_evo2_generation --model_name evo2_7b
```

##### Lockfile hygiene with UV

Keep the base env managed by uv sync, and overlay Torch/TE/FA/Evo2 on the GPU nodes via pip (or site modules).

```python
uv add --extra infer-evo2 evo2
uv add flash-attn==2.8.0.post2
uv add transformer-engine>=2.0.0
uv lock && uv sync
```

Add packages to the project and update uv.lock as needed.
```bash
uv add <pkg>==<ver>
# remove
uv remove <pkg>
# upgrade a specific package in the lock
uv lock --upgrade-package <pkg>
# enforce exact lock during CI
uv sync --frozen
```

##### Cluster allocation hygiene

Cap all CPU thread pools to your allocation:
```bash
# Match thread counts to the slots SGE gave you
export OMP_NUM_THREADS=${NSLOTS:-1}
export MKL_NUM_THREADS=${NSLOTS:-1}
export OPENBLAS_NUM_THREADS=${NSLOTS:-1}
export BLIS_NUM_THREADS=${NSLOTS:-1}
export NUMEXPR_NUM_THREADS=${NSLOTS:-1}
export OMP_DYNAMIC=false
# HF tokenizers can spin up threads too
export TOKENIZERS_PARALLELISM=false
```

---

@e-south
