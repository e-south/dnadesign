# dnadesign

`dnadesign` is a collection of modular bioinformatic pipelines and helper packages related to biological sequence design.

- [Directory layout](#directory-layout)
- [Tools](#tools)
- [Installation](#installation)
  - [Local install](#local-install)
  - [Running `dnadesign` CLIs](#running-dnadesign-clis)
  - [Running notebooks](#running-notebooks)
  - [Installing `dnadesign` for GPU flows](#installing--dnadesign--for-GPU-flows)
- [Maintaining dependencies](#maintaining-dependencies)

---

### Directory layout

```text
dnadesign/
├─ README.md            # High-level project documentation
├─ pyproject.toml
├─ uv.lock
└── src/
    └── dnadesign/ 
        ├── permuter/    # in silico deep mutational scanning
        ├── infer/       # model-agnostic inference (Evo2 adapter)
        ├── densegen/    # string-packing nucleic acid assembly           
        ├── opal/        # active-learning engine
        └── ...
```

---

### Tools

1. [**usr**](src/dnadesign/usr) 

      **usr (Universal Sequence Record)** consists of utility commands to inspect datasets/Parquet files used across the `dnadesign` project.

2. [**densegen**](src/dnadesign/densegen) 
   
      **densegen** is a DNA sequence design pipeline built on the integer linear programming framework from the [`dense-arrays`](https://github.com/e-south/dense-arrays) package.

2. [**infer**](src/dnadesign/infer)  

      **infer** is a model-agnostic wrapper for DNA/protein language models (e.g., [Evo2](https://github.com/ArcInstitute/evo2/tree/main)).

3. [**opal**](src/dnadesign/opal)

      **opal** is an [EVOLVEpro-style](https://www.science.org/doi/10.1126/science.adr6006) active-learning tool for DNA/protein sequence design campaigns.

3. [**cluster**](src/dnadesign/cluster) 
  
      **cluster** is a Parquet/CSV-first tool for Leiden clustering, UMAP visualisation, and a mix of other analyses.

4. [**billboard**](src/dnadesign)  

      **billboard** quantifies the regulatory diversity of dense-array DNA libraries generated by **densegen**.

5.  [**libshuffle**](src/dnadesign/libshuffle)

      **libshuffle** iteratively subsamples sequence libraries from the sibling **sequences** directory and computes diversity metrics using the **billboard** pipeline as its engine.

6.	[**nmf**](src/dnadesign/nmf)

      **nmf** applies Non-Negative Matrix Factorization (NMF) to a library of sequences generated by **densegen** to uncover higher-order transcription factor binding site combinations.

7.  [**latdna**](src/dnadesign/latdna)

      **latdna** is a pipeline for latent space analysis of DNA sequences.

8. [**cruncher**](src/dnadesign/cruncher)

      **cruncher** is a pipeline that parses TF position-weight matrices (MEME, JASPAR, etc.) via plug-in parsers, and then runs a discrete Categorical Gibbs optimiser (or other plug-ins) to discover short DNA sequences that score highly on one or more TFs.

9. [**tfkdanalysis**](src/dnadesign/tfkdanalysis)

      **tfkdanalysis** is a pipeline for analyzing transcription factor knockdown (TFKD) effects using PPTP-seq (Promoter responses to TF perturbation sequencing) data—a high-throughput approach described in [Han *et al.* (2023)](https://doi.org/10.1038/s41467-023-41572-4).

12. [**aligner**](src/dnadesign/aligner)

      **aligner** is a wrapper for Biopython's [PairwiseAligner](https://biopython.org/docs/dev/Tutorial/chapter_pairwise.html#chapter-pairwise), which is a class for computing Needleman–Wunsch global alignment scores between nucleotide sequences.

13. [**permuter**](src/dnadesign/permuter)

      **permuter** permuter is a pipeline for biological sequence permutation and subsequent evaluation workflows.
14. [**archived**](src/dnadesign/archived)

      **archived** contains a mix of old legacy projects and prototypes.

---

### Installation

This repo is managed with [**uv**](https://docs.astral.sh/uv/):

- `pyproject.toml` declares dependencies (runtime + optional extras).
- `uv.lock` is the fully pinned dependency graph.
- `.venv/` is the project virtual environment (created automatically by uv).

**Two key commands:**

- `uv sync` installs everything from the lockfile into `.venv` (and creates `.venv` if it doesn’t exist).
- `uv run <cmd>` runs commands inside the project environment without requiring `source .venv/bin/activate`.

#### Install uv

macOS/Linux, or find other methods [here](https://docs.astral.sh/uv/getting-started/installation/):
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
# ensure your uv bin dir is on PATH
```

#### Clone repo
```bash
git clone https://github.com/e-south/dnadesign.git
cd dnadesign
```

#### Local install

This is the default way to start working with most pipelines.

1. Ensure Python 3.12 is available:

      ```bash
      uv python install 3.12
      ```

2. Create/sync the environment from the committed lockfile:

      ```bash
      uv sync --locked
      ```

3. Sanity checks:

      ```bash
      uv run python -c "import dnadesign, pandas, pyarrow; print('ok')"
      uv run usr ls || true
      ```

#### Dev tools (tests + lint)

Dev tooling is opt-in via a dependency group.

```bash
uv sync --locked --group dev
uv run ruff --version
uv run pytest -q
```

---

#### Running `dnadesign` CLIs

This repo defines console scripts like usr, opal, dense, infer, etc.

##### Option A: no `.venv` activation — use `uv run`

```bash
uv run usr --help
uv run usr ls

uv run opal --help
uv run dense --help
uv run infer --help
uv run cluster --help
uv run permuter --help
uv run baserender --help
```

##### Option B: traditional — activate `.venv`
      
```bash
source .venv/bin/activate
usr --help
usr ls
deactivate
```

---

#### Running notebooks

There are two ways to use marimo:

##### 1. Install marimo into the project

```bash
uv sync --locked --group notebooks
uv run marimo edit notebooks/example.py
```

This runs marimo inside your project environment, so it can import `dnadesign` and anything in `uv.lock`.

##### 2. Sandboxed / self-contained marimo notebooks (inline dependencies)

Marimo can manage per-notebook sandbox environments using inline metadata. This is great for sharable notebooks.

1. Create/edit a sandbox notebook (marimo installed temporarily via uvx).

      ```bash
      uvx marimo edit --sandbox notebooks/sandbox_example.py
      ```

2. Run a sandbox notebook as a script.

      ```bash
      uv run notebooks/sandbox_example.py
      ```

3. Make the sandbox notebook use your local `dnadesign` repo in editable mode.

      From the repo root:

      ```bash
      uv add --script notebooks/sandbox_example.py . --editable
      ```

      This writes inline metadata into the notebook so its sandbox can install dnadesign from your local checkout in editable mode.

4. Add/remove sandbox dependencies (only affects the notebook file)

      ```bash
      uv add    --script notebooks/sandbox_example.py numpy
      uv remove --script notebooks/sandbox_example.py numpy
      ```

#### Optional: `dense-arrays` dependency

`dense-arrays` is included as a git-sourced dependency and is pinned in `uv.lock`, so users do not need to clone it manually.

If you want to hack on `dense-arrays` locally (editable), clone it and override the dependency to a local path:

```bash
git clone https://github.com/e-south/dense-arrays ../dense-arrays
uv add ../dense-arrays --editable
uv lock
uv sync
```

#### Installing `dnadesign` for GPU flows

Some pipelines in `dnadesign` are designed to run on a [shared computing cluster](https://www.bu.edu/tech/support/research/system-usage/connect-scc/scc-ondemand/), such as solving dense arrays with [Gurobi](https://www.gurobi.com/), or running inference with [Evo 2](https://github.com/ArcInstitute/evo2), which requires access to CUDA and GPUs.

The GPU inference stack is provided as an optional extra (`infer-evo2`) and is Linux-only, so:

- `uv sync --locked` stays CPU-safe everywhere
- GPU users explicitly opt in when on the right machine

Below uses CUDA 12.6 wheels as an example; change the index URL to match your cluster’s CUDA toolchain.

#####  1. (Optional) Request an interactive GPU session
SCC Interactive Session Resource Request Example:

> - **densegen** workflow:
>   - Modules: miniconda gurobi
>   - Cores: 16  
>   - GPUs: 0  
> - **infer** workflow:  
>   - Modules: cuda miniconda
>   - Cores: 3  
>   - GPUs: 1  
>   - GPU Compute Capability: 8.9  
>   - Extra options: `-l mem_per_core=8G`  

Check your cluster documentation for submission details.

##### 2. Put uv caches/temp on project space (HPC-friendly)

Add to `~/.bashrc` or your job script (adjust paths):
```bash
export UV_CACHE_DIR="${UV_CACHE_DIR:-/project/dunlop/esouth/.uvcache}"
export UV_LINK_MODE=copy
export TMPDIR="${TMPDIR:-/project/dunlop/esouth/.uvtmp}"
[ -d "$UV_CACHE_DIR" ] || mkdir -p "$UV_CACHE_DIR"
[ -d "$TMPDIR" ] || mkdir -p "$TMPDIR"
export PYTHONNOUSERSITE=1
```

##### 3. Clone + base sync
```bash
git clone https://github.com/e-south/dnadesign.git
cd dnadesign

uv python install 3.12
uv sync --locked
```

##### 4. Load CUDA toolchain (site-specific)
```bash
module load cuda/12.6
module load gcc/10.2.0

export CUDA_HOME="$CUDA_PATH"
export CUDACXX="$CUDA_HOME/bin/nvcc"
export PATH="$CUDA_HOME/bin:$PATH"

# Pick an arch that matches your GPU
export TORCH_CUDA_ARCH_LIST="${TORCH_CUDA_ARCH_LIST:-8.9}"
export FORCE_CUDA=1
```

Sanity:
```bash
nvcc --version
gcc --version
```

##### 5) Install the GPU inference extra

Staged install (Torch first → TE/FA → Evo2)
```bash
# Stage 1: Torch only (skip native extensions + evo2)
uv sync --locked --extra infer-evo2 \
  --no-install-package flash-attn \
  --no-install-package transformer-engine \
  --no-install-package evo2

# Stage 2: build/install TE + FA (still skip evo2)
uv sync --locked --extra infer-evo2 \
  --no-install-package evo2

# Stage 3: install evo2
uv sync --locked --extra infer-evo2
```

This will install:

- PyTorch (from the CUDA wheel index configured in pyproject.toml)
- transformer-engine
- flash-attn (from a pinned git tag)
- evo2
- build helpers (ninja/packaging)

Validate:

```bash
uv run python - <<'PY'
import torch
print("Torch:", torch.__version__)
print("CUDA avail:", torch.cuda.is_available())
print("Torch CUDA:", torch.version.cuda)
PY

uv run python - <<'PY'
from transformer_engine.pytorch import Linear
print("TransformerEngine OK")
PY

uv run python - <<'PY'
import importlib.util as iu
print("flash_attn present:", iu.find_spec("flash_attn") is not None)
PY
```

#### Maintaining dependencies

If you want to change dependencies, prefer `uv add` / `uv remove`:

- Add a runtime dependency:

  ```bash
  uv add <package>
  ```

- Add to a dependency group (examples):

  ```bash
  uv add --group dev <package>
  uv add --group notebooks marimo
  ```

- Remove:

  ```bash
  uv remove <package>
  ```

Then commit `pyproject.toml` + `uv.lock`.

If you edit `pyproject.toml` by hand, regenerate `uv.lock`:

```bash
uv lock
```

New users should then run:

```bash
uv sync --locked
```

---

@e-south
